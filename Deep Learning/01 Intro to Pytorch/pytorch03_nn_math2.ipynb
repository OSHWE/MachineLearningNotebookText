
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Feed Forward in PyTorch to Real Data\n",
    "Last time, we looked at simple feed forward with some randomly generated numbers. This time we will use real-world image data. The goal is to eventually train a network that takes a 28x28 pixel grayscale image of a hand written number between 0 and 9 and accurately classfies it. \n",
    "\n",
    "Because there are 10 possible digits that an input can be classified as, our network will need to have 10 outputs. Each of the 10 outputs will represent a probability of the input being classified as one of the 10 numbers. For example, output 1 will represent the probability that th input is a 1. Output 2 will be the probability that the input is a 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "We will be using grayscale image data, which is nothing but numeric values ranging from 0 to 255 for black to white. In order for a neural network to train well, input data needs to be normalized so that it all falls within a fairly compact range. Also, all PyTorch implementations require that incoming data be in tensor format. \n",
    "\n",
    "Below is a simple transform that takes in pixel data from an image, converts it to a `torch.tensor` and then standardizes it to a range between -1 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders\n",
    "PyTorch comes pre-packaged with some common data sets, which allows you to learn to use PyTorch rather than fumbling together your own dataset. \n",
    "\n",
    "Additionally, PyTorch has an object called a `DataLoader` which is nothing more than an efficient way to shuffle chunk your data into smaller pieces to feed to a neural network. \n",
    "\n",
    "If you do need to create a custom dataset, but want to use PyTorch's awesome features, here is a tutorial on how to create and extend their `Dataset` and `DataLoader` code: \n",
    "\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "For now, here is how you load the standard issue MNIST dataset into a `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and load MNIST training data:\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batch_size` is nothing more than the number of images to feed into your network at a time. Your choice of this number will be dictated by the amount of memory you want to use at a time. \n",
    "\n",
    "## Displaying the Data\n",
    "Alright, now we have our data and we'd like to take a look at it. We will oad our first 'batch' of images, which should be of size 64. \n",
    "\n",
    "Next, we will display the first image in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Get first batch of images from the trainloader\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2796d1373d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display first image in first batch:\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Network Weights and Biases\n",
    "Now, we initialize our 'Network' in the exact manner that was covered in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture:\n",
    "n_in = 784\n",
    "n_hidden = 256\n",
    "n_out = 10\n",
    "\n",
    "# randomly initialize weight matrices:\n",
    "W1 = torch.randn((n_in, n_hidden))\n",
    "W2 = torch.randn((n_hidden, n_out))\n",
    "b1 = torch.randn((1, n_hidden))\n",
    "b2 = torch.randn((1, n_out))\n",
    "\n",
    "# define activation function:\n",
    "def activation(x):\n",
    "    return 1/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward With a New Twist\n",
    "In the previous section, we used the sigmoid activation function on the output layer. This time, as mentioned, our network will have 10 outputs, one for the probability of each possible digit. For this reason, we will use a __Softmax__ activation function.\n",
    "\n",
    "$$\\text{out}_i = \\frac{e^{z_i}}{\\sum_{j}e^{z_j}}$$\n",
    "\n",
    "The Softmax function does two things for us:\n",
    "\n",
    "1. It squishes the outputs of the final layer to each be betweein 0 and 1. \n",
    "2. It ensures that the sum of all probabilites adds to equal 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feedforward:\n",
    "a1 = activation(torch.mm(images.reshape(64, -1), W1) + b1)\n",
    "out = torch.mm(a1, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64 batches, each with 10 output probabilites.\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Softmax function:\n",
    "def softmax(z):\n",
    "    ez = torch.exp(z)\n",
    "    return ez/ez.sum(dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Because the output of the network has dimensions (64, 10) representing 64 batches of 10 outputs each, it is important that we apply softmax to the right dimension. Each column of data represents one of 10 outputs, and so it is to these columns that we want to apply the softmax function. Hence, you see `dim=1` in the function above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilites should sum to 1 with softmax:\n",
    "probabilities = softmax(out)\n",
    "probabilities.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Our Results\n",
    "Now we have run the first 64 images through our network. Lets take a look at our first image and our networks prediction of what that image represents. Since the network is 'untrained', we should get pretty bad predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2796d186880>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANhElEQVR4nO3df6hc9ZnH8c/HmKgxVaMh2axG2y2KLoGNEoLQopHQkhUhFlESyJINZW/BurQYcMVFI4hQlm2L/hNJUBKXrrXQZhOhrJWkqPtHiteYTWJjo9GYpgk3FkUTo8Srz/5xT5abZOY71znzq3neLwgzc5455zyMfu45M9+Z83VECMDZ75x+NwCgNwg7kARhB5Ig7EAShB1I4txe7sw2H/0DXRYRbrS81pHd9mLbf7D9lu3762wLQHe53XF225Mk7ZX0LUkHJb0iaVlE/L6wDkd2oMu6cWRfIOmtiHg7Ik5I+rmkJTW2B6CL6oT9ckl/HPf4YLXsFLaHbA/bHq6xLwA11fmArtGpwhmn6RGxVtJaidN4oJ/qHNkPSpoz7vEVkg7VawdAt9QJ+yuSrrb9NdtTJC2VtLkzbQHotLZP4yNi1PY9kp6XNEnSUxHxesc6A9BRbQ+9tbUz3rMDXdeVL9UA+MtB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii7fnZJcn2fklHJX0uaTQi5neiKQCdVyvslVsi4s8d2A6ALuI0HkiibthD0m9sv2p7qNETbA/ZHrY9XHNfAGpwRLS/sv3XEXHI9kxJL0j654h4qfD89ncGYEIiwo2W1zqyR8Sh6vaIpI2SFtTZHoDuaTvsti+0/ZWT9yV9W9LuTjUGoLPqfBo/S9JG2ye3858R8d8d6QqnWLhwYbH+9NNPN61dccUVxXU/+uijYv2iiy4q1qv//k2V3iZ+9tlnxXW3bdtWrO/du7dYf+SRR5rWDhw4UFz3bNR22CPibUl/18FeAHQRQ29AEoQdSIKwA0kQdiAJwg4kUesbdF96Z3yDrqFbbrmlWH/uueeK9alTp3aynbPG6Oho01qrYbtHH320WN+0aVOxfvz48WK9m7ryDToAfzkIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtl74OKLLy7W33333WK91c9Mu+mDDz4o1o8ePVqs33TTTW3v+8477yzWZ82aVawvXbq0ae2CCy4ornvZZZcV6x9//HGx/vzzzxfrK1eubFpr9Zq2wjg7kBxhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHsPlC71LEnLly+vtf3SmO/q1auL627durVY37dvX7E+c+bMWuv3y7Rp04r1m2++uVh/6KGHivW5c+cW659++mnTWqtLh+/atatYZ5wdSI6wA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0H3njjjWL9mmuuqbX9Bx98sGmt1fXP0R1z5swp1kvj8O+9915x3eHh4WK97XF220/ZPmJ797hll9p+wfab1e30VtsB0F8TOY1fL2nxacvul7QlIq6WtKV6DGCAtQx7RLwk6f3TFi+RtKG6v0HS7R3uC0CHndvmerMi4rAkRcRh202/IG17SNJQm/sB0CHthn3CImKtpLVS3g/ogEHQ7tDbiO3ZklTdHulcSwC6od2wb5a0orq/QlJ5/loAfddynN32M5IWSpohaUTSakn/JekXkq6UdEDSnRFx+od4jbaV8jS+9NtlSZoyZUqt9efNm9e01moecpx9mo2zt3zPHhHLmpQW1eoIQE/xdVkgCcIOJEHYgSQIO5AEYQeS6Po36DK48sori/Vzzqn3N3X9+vXFOsNrmAiO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBJeS7oBW4+jHjx8v1lv9xLXVtMd33XVX09prr71WXBdnH6ZsBpIj7EAShB1IgrADSRB2IAnCDiRB2IEkGGfvgfffL19l+5JLLqm1/dHR0bZqE/Hhhx8W6xs3bizW77333qa1VpfIRnsYZweSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJBhn74Hrr7++WF+3bl2xfsMNN3SynZ56+eWXm9YWL15cXPeTTz7pdDsptD3Obvsp20ds7x637GHbf7K9o/p3ayebBdB5EzmNXy+p0Z/gn0bEvOrfrzvbFoBOaxn2iHhJUvn7ngAGXp0P6O6xvbM6zZ/e7Em2h2wP2x6usS8ANbUb9jWSvi5pnqTDkn7c7IkRsTYi5kfE/Db3BaAD2gp7RIxExOcR8YWkdZIWdLYtAJ3WVthtzx738DuSdjd7LoDB0HKc3fYzkhZKmiFpRNLq6vE8SSFpv6TvRcThljtLOs7eytSpU4v1uXPndm3f1157bbG+fPnyYn3RokXFut1wyFeS9MQTTxTXvfvuu4t1NNZsnP3cCay4rMHiJ2t3BKCn+LoskARhB5Ig7EAShB1IgrADSfATV9TSajrq888/v2mt1WWqp09v+i1sFHApaSA5wg4kQdiBJAg7kARhB5Ig7EAShB1IouWv3pDbVVddVaxPmjSpR52gLo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+woWrp0abE+efLkHnWCujiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLOjaNWqVV3b9po1a7q2bZyp5ZHd9hzbv7W9x/brtn9QLb/U9gu236xuuaI/MMAmcho/KmlVRFwn6UZJ37f9t5Lul7QlIq6WtKV6DGBAtQx7RByOiO3V/aOS9ki6XNISSRuqp22QdHu3mgRQ35d6z277q5Kul/Q7SbMi4rA09gfB9swm6wxJGqrXJoC6Jhx229Mk/VLSDyPiI7vh3HFniIi1ktZW22BiR6BPJjT0ZnuyxoL+s4j4VbV4xPbsqj5b0pHutAigE1oe2T12CH9S0p6I+Mm40mZJKyT9qLrd1JUOUcs555T/nj/77LPF+owZM2rt/9ixY01rjz32WK1t48uZyGn8NyT9g6RdtndUyx7QWMh/Yfu7kg5IurM7LQLohJZhj4j/kdTsDfqizrYDoFv4uiyQBGEHkiDsQBKEHUiCsANJ8BPXAXDjjTcW69u2bWt72/fdd1+xfscdd7S97YnYunVr09rIyEhX941TcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQc0buLx3ClmsZaXVK59JtwSdq5c2fT2rp164rrTpkypVhv5Z133inWr7vuuqa1EydO1No3GouIhr9S5cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nwe/YBsH379mL98ccfL9bPO++8TrZzin379hXrixaVLzDMWPrg4MgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0m0/D277TmSnpb0V5K+kLQ2Ih6z/bCkf5L0XvXUByLi1y22xe/Z27B58+Zi/bbbbmt72y+++GKxvnLlymJ9//79be8b3dHs9+wT+VLNqKRVEbHd9lckvWr7har204j49041CaB7JjI/+2FJh6v7R23vkXR5txsD0Flf6j277a9Kul7S76pF99jeafsp29ObrDNke9j2cK1OAdQy4bDbnibpl5J+GBEfSVoj6euS5mnsyP/jRutFxNqImB8R8zvQL4A2TSjstidrLOg/i4hfSVJEjETE5xHxhaR1khZ0r00AdbUMu21LelLSnoj4ybjls8c97TuSdne+PQCdMpGht29KelnSLo0NvUnSA5KWaewUPiTtl/S96sO80rYYegO6rNnQG9eNB84yXDceSI6wA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRK+nbP6zpHfHPZ5RLRtEg9rboPYl0Vu7OtnbVc0KPf09+xk7t4cH9dp0g9rboPYl0Vu7etUbp/FAEoQdSKLfYV/b5/2XDGpvg9qXRG/t6klvfX3PDqB3+n1kB9AjhB1Ioi9ht73Y9h9sv2X7/n700Izt/bZ32d7R7/npqjn0jtjePW7ZpbZfsP1mddtwjr0+9faw7T9Vr90O27f2qbc5tn9re4/t123/oFre19eu0FdPXreev2e3PUnSXknfknRQ0iuSlkXE73vaSBO290uaHxF9/wKG7ZskHZP0dETMrZb9m6T3I+JH1R/K6RHxLwPS28OSjvV7Gu9qtqLZ46cZl3S7pH9UH1+7Ql93qQevWz+O7AskvRURb0fECUk/l7SkD30MvIh4SdL7py1eImlDdX+Dxv5n6bkmvQ2EiDgcEdur+0clnZxmvK+vXaGvnuhH2C+X9Mdxjw9qsOZ7D0m/sf2q7aF+N9PArJPTbFW3M/vcz+laTuPdS6dNMz4wr10705/X1Y+wN5qaZpDG/74RETdI+ntJ369OVzExE5rGu1caTDM+ENqd/ryufoT9oKQ54x5fIelQH/poKCIOVbdHJG3U4E1FPXJyBt3q9kif+/l/gzSNd6NpxjUAr10/pz/vR9hfkXS17a/ZniJpqaTNfejjDLYvrD44ke0LJX1bgzcV9WZJK6r7KyRt6mMvpxiUabybTTOuPr92fZ/+PCJ6/k/SrRr7RH6fpH/tRw9N+vobSf9b/Xu9371JekZjp3WfaeyM6LuSLpO0RdKb1e2lA9Tbf2hsau+dGgvW7D719k2NvTXcKWlH9e/Wfr92hb568rrxdVkgCb5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/B/PNmTEJjMJmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2796d199eb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPoklEQVR4nO3dfZBdd13H8feHTTPQAlOGLIJJIEEDGJFKXQNYrWitpMAQUGZMURhUJtahPOg4Up0RRvmrg+MwQiGTKVEcgQyWghkMBHwAHBDMtrSlaQmGAM0SsMuD1AJjGvj6x70wt9vd3LPp3Xs3v75fM3dyHn45v09vdz9z9uw9J6kqJElnvwdNOoAkaTQsdElqhIUuSY2w0CWpERa6JDVizaQmXrduXW3atGlS00vSWemGG274WlVNL7ZvYoW+adMmZmdnJzW9JJ2VknxpqX1ecpGkRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZM7E5RLe2iN100lnk+/oqPj2UeSePhGbokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJakSnQk+yPcmRJEeTXLXEmGcmuSnJ4SQfHW1MSdIwQ5+HnmQKuAa4FJgDDiXZX1W3DYw5H3gLsL2q7kjyqJUKLElaXJcz9G3A0ao6VlUngX3AjgVjXgRcX1V3AFTVnaONKUkapkuhrweOD6zP9bcNegLwiCQfSXJDkpcsdqAku5LMJpmdn58/s8SSpEV1KfQssq0WrK8BfgZ4DvAs4M+SPOE+f6lqT1XNVNXM9PT0ssNKkpbW5d8UnQM2DqxvAE4sMuZrVfVt4NtJPgZcAHxuJCklSUN1OUM/BGxJsjnJWmAnsH/BmH8EfiHJmiTnAk8Dbh9tVEnS6Qw9Q6+qU0muBA4CU8Deqjqc5Ir+/t1VdXuSDwK3AN8Hrq2qW1cyuCTp3rpccqGqDgAHFmzbvWD9DcAbRhdNkrQc3ikqSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiM6FXqS7UmOJDma5KpF9j8zybeS3NR/vXb0USVJp7Nm2IAkU8A1wKXAHHAoyf6qum3B0H+vqueuQEZJUgddztC3AUer6lhVnQT2ATtWNpYkabm6FPp64PjA+lx/20LPSHJzkg8k+cnFDpRkV5LZJLPz8/NnEFeStJQuhZ5FttWC9RuBx1XVBcCbgPctdqCq2lNVM1U1Mz09vbykkqTT6lLoc8DGgfUNwInBAVV1V1Xd3V8+AJyTZN3IUkqShupS6IeALUk2J1kL7AT2Dw5I8ugk6S9v6x/366MOK0la2tBPuVTVqSRXAgeBKWBvVR1OckV//27ghcDvJzkFfBfYWVULL8tIklbQ0EKHH15GObBg2+6B5TcDbx5tNEnScninqCQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJakSnQk+yPcmRJEeTXHWacT+b5HtJXji6iJKkLoYWepIp4BrgMmArcHmSrUuMuxo4OOqQkqThupyhbwOOVtWxqjoJ7AN2LDLuFcB7gDtHmE+S1FGXQl8PHB9Yn+tv+6Ek64EXALtPd6Aku5LMJpmdn59fblZJ0ml0KfQssq0WrL8ReE1Vfe90B6qqPVU1U1Uz09PTXTNKkjpY02HMHLBxYH0DcGLBmBlgXxKAdcCzk5yqqveNJKUkaaguhX4I2JJkM/BlYCfwosEBVbX5B8tJ/hZ4v2UuSeM1tNCr6lSSK+l9emUK2FtVh5Nc0d9/2uvmkqTx6HKGTlUdAA4s2LZokVfVS+9/LEnScnmnqCQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJakSnQk+yPcmRJEeTXLXI/h1JbklyU5LZJD8/+qiSpNNZM2xAkingGuBSYA44lGR/Vd02MOxfgP1VVUmeArwbeNJKBJak1eCC6w6Oba6bX/isTuO6nKFvA45W1bGqOgnsA3YMDqiqu6uq+qvnAYUkaay6FPp64PjA+lx/270keUGSzwL/BPzOaOJJkrrqUuhZZNt9zsCr6r1V9STg+cDrFz1Qsqt/jX12fn5+eUklSafVpdDngI0D6xuAE0sNrqqPAT+WZN0i+/ZU1UxVzUxPTy87rCRpaV0K/RCwJcnmJGuBncD+wQFJfjxJ+ssXAmuBr486rCRpaUM/5VJVp5JcCRwEpoC9VXU4yRX9/buBXwdekuQe4LvAbwz8klSSNAZDCx2gqg4ABxZs2z2wfDVw9WijSZKWwztFJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWpEp0JPsj3JkSRHk1y1yP7fTHJL//WJJBeMPqok6XSGFnqSKeAa4DJgK3B5kq0Lhn0B+MWqegrwemDPqINKkk6vyxn6NuBoVR2rqpPAPmDH4ICq+kRVfbO/+klgw2hjSpKG6VLo64HjA+tz/W1L+V3gA4vtSLIryWyS2fn5+e4pJUlDdSn0LLKtFh2Y/BK9Qn/NYvurak9VzVTVzPT0dPeUkqSh1nQYMwdsHFjfAJxYOCjJU4Brgcuq6uujiSdJ6qrLGfohYEuSzUnWAjuB/YMDkjwWuB54cVV9bvQxJUnDDD1Dr6pTSa4EDgJTwN6qOpzkiv7+3cBrgUcCb0kCcKqqZlYutiRpoS6XXKiqA8CBBdt2Dyy/DHjZaKNJkpbDO0UlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjOhV6ku1JjiQ5muSqRfY/Kcl/JPm/JH80+piSpGHWDBuQZAq4BrgUmAMOJdlfVbcNDPsG8Erg+SuSUpI0VJcz9G3A0ao6VlUngX3AjsEBVXVnVR0C7lmBjJKkDroU+nrg+MD6XH/bsiXZlWQ2yez8/PyZHEKStIQuhZ5FttWZTFZVe6pqpqpmpqenz+QQkqQldCn0OWDjwPoG4MTKxJEknakuhX4I2JJkc5K1wE5g/8rGkiQt19BPuVTVqSRXAgeBKWBvVR1OckV//+4kjwZmgYcD30/yamBrVd21gtklSQOGFjpAVR0ADizYtntg+av0LsVIkibEO0UlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY3o9A9cPFDc8Rc/Nba5Hvvaz4xtLkkPDJ6hS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZ0KvQk25McSXI0yVWL7E+Sv+7vvyXJhaOPKkk6naGFnmQKuAa4DNgKXJ5k64JhlwFb+q9dwFtHnFOSNESXM/RtwNGqOlZVJ4F9wI4FY3YAf1c9nwTOT/KYEWeVJJ1GlztF1wPHB9bngKd1GLMe+MrgoCS76J3BA9yd5Miy0t7XOuBr9/MY99eZZXhdJp4jr5x8hhWyGnKshgywOnKshgywOnKcUYYF36mPW2pcl0Jf7Lu+zmAMVbUH2NNhzk6SzFbVzKiOd7ZmWC05VkOG1ZJjNWRYLTlWQ4bVkmOlM3S55DIHbBxY3wCcOIMxkqQV1KXQDwFbkmxOshbYCexfMGY/8JL+p12eDnyrqr6y8ECSpJUz9JJLVZ1KciVwEJgC9lbV4SRX9PfvBg4AzwaOAt8BfnvlIt/LyC7f3A+rIQOsjhyrIQOsjhyrIQOsjhyrIQOsjhwrmiFV97nULUk6C3mnqCQ1wkKXpEaclYU+7FEEY8qwN8mdSW6dxPz9DBuT/FuS25McTvKqCeV4cJL/THJzP8efTyJHP8tUkk8nef8EM3wxyWeS3JRkdkIZzk9yXZLP9r8+njGBDE/svwc/eN2V5NUTyPEH/a/LW5O8K8mDx52hn+NV/QyHV+x9qKqz6kXvF7OfBx4PrAVuBrZOIMfFwIXArRN8Lx4DXNhffhjwuQm9FwEe2l8+B/gU8PQJvSd/CLwTeP8E/798EVg3qfn7Gd4OvKy/vBY4f8J5poCvAo8b87zrgS8AD+mvvxt46QT++58M3AqcS+/DKP8MbBn1PGfjGXqXRxGsuKr6GPCNcc+7IMNXqurG/vL/ArfT+wIed46qqrv7q+f0X2P/bXuSDcBzgGvHPfdqkuTh9E443gZQVSer6n8mm4pLgM9X1ZcmMPca4CFJ1tAr1EncI/MTwCer6jtVdQr4KPCCUU9yNhb6Uo8ZeEBLsgl4Kr2z40nMP5XkJuBO4MNVNYkcbwT+GPj+BOYeVMCHktzQf9zFuD0emAf+pn/56dok500gx6CdwLvGPWlVfRn4S+AOeo8i+VZVfWjcOeidnV+c5JFJzqX3Me+NQ/7Osp2Nhd7pMQMPJEkeCrwHeHVV3TWJDFX1var6aXp3CW9L8uRxzp/kucCdVXXDOOddwkVVdSG9p5C+PMnFY55/Db3LgW+tqqcC3wYm8rsmgP4Nic8D/mECcz+C3k/wm4EfBc5L8lvjzlFVtwNXAx8GPkjvUvGpUc9zNha6jxkYkOQcemX+jqq6ftJ5+j/afwTYPuapLwKel+SL9C7D/XKSvx9zBgCq6kT/zzuB99K7TDhOc8DcwE9J19Er+Em5DLixqv57AnP/CvCFqpqvqnuA64Gfm0AOquptVXVhVV1M73Ltf416jrOx0Ls8iuABIUnoXSe9var+aoI5ppOc319+CL1vos+OM0NV/UlVbaiqTfS+Jv61qsZ+JpbkvCQP+8Ey8Kv0ftwem6r6KnA8yRP7my4BbhtnhgUuZwKXW/ruAJ6e5Nz+98sl9H7XNHZJHtX/87HAr7EC70mXpy2uKrXEowjGnSPJu4BnAuuSzAGvq6q3jTnGRcCLgc/0r18D/GlVHRhzjscAb+//YygPAt5dVRP72OCE/Qjw3l53sAZ4Z1V9cAI5XgG8o3/Sc4zxPY7jXvrXiy8Ffm8S81fVp5JcB9xI7xLHp5ncIwDek+SRwD3Ay6vqm6OewFv/JakRZ+MlF0nSIix0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1Ij/B9Ri/mfDTBivAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the probability distribution of the given image\n",
    "sns.barplot(x=np.arange(10), y=probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.3293e-07, 3.2592e-02, 6.5972e-01, 5.4755e-04, 6.4431e-08, 1.2207e-08,\n",
       "        2.5017e-07, 1.8994e-18, 3.8105e-10, 3.0714e-01])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sure enough, the network thinks this one is a three (and it's 100 percent sure of itself!)\n",
    "probabilities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the network did not guess correctly. It believes the highest probability is that the input image is a 2 (66%). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}